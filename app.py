import streamlit as st
import json
import os
import base64
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
import pandas as pd
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="F1 í…Œë§ˆ ì°¨ ì¶”ì²œ", page_icon="ğŸ", layout="centered")

def set_background(image_file_path):
    if os.path.exists(image_file_path):
        with open(image_file_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode()
            css = f"""
            <style>
            .stApp {{
                background-image: url("data:image/jpeg;base64,{encoded_string}");
                background-size: cover;
                background-position: center;
                background-repeat: no-repeat;
                background-attachment: fixed;
            }}
            </style>
            """
            st.markdown(css, unsafe_allow_html=True)

# ë¡œì»¬ ì´ë¯¸ì§€ë¡œ ë°°ê²½ ì„¤ì • (íŒŒì¼ì´ ì¡´ì¬í•  ë•Œë§Œ)
set_background("C:/Users/1/Downloads/f1.jpg")

# F1 ë¡œê³  í‘œì‹œ
st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/F1.svg/320px-F1.svg.png", width=180)

# ë ˆì´ì‹± ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸
st.markdown(
    """
    <h1 style="text-align: center; color: #e10600; font-family:Verdana; font-size: 48px;"><div style="display: inline-block; line-height: 1.2;">ë‚˜ë§Œì˜ ë“œë¦¼ì¹´! ğŸï¸<br>ì‹ ì°¨ ì¶”ì²œ ì±—ë´‡ ğŸ</div></h1>
    """,
    unsafe_allow_html=True
)

# ìë™ì°¨ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    with open('data/hyundai.json', 'r', encoding='utf-8') as f:
        cars = json.load(f)
except FileNotFoundError:
    st.error("ìë™ì°¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'data/hyundai.json' íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ìë™ì°¨ ì •ë³´ë¥¼ ìš”ì•½ëœ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
car_docs = []
for car in cars:
    doc = f"{car['brand']}ì˜ {car['model_name']}ì€(ëŠ”) {car['car_type']} ìœ í˜•ì˜ ì°¨ëŸ‰ìœ¼ë¡œ, {car['fuel_type']}ì„ ì‚¬ìš©í•˜ë©°, ê°€ê²©ì€ ì•½ {car['price']}ë§Œì›ì…ë‹ˆë‹¤. ì—°ë¹„ëŠ” {car['fuel_efficiency']}km/l, ìµœëŒ€ ì£¼í–‰ ê°€ëŠ¥ ê±°ë¦¬ëŠ” {car['range_km']}kmì…ë‹ˆë‹¤. {car['seats']}ì¸ìŠ¹ì´ë©°, ì‚¬ìš© ê°€ëŠ¥í•œ ìƒ‰ìƒì€ {', '.join(car['available_colors'])}ì…ë‹ˆë‹¤. ìš”ì•½: {car['short_desc']}"
    car_docs.append(doc)

# CSV ì €ì¥ íŒŒì¼ ê²½ë¡œ
chat_history_csv_path = "chat_history.csv"

# ì‚¬ìš©ì ì•„ì´ë”” ì…ë ¥ ë° ì„¸ì…˜ ì´ˆê¸°í™”
if "user_id" not in st.session_state or st.session_state["user_id"] is None:
    st.markdown('<p style="color: white; font-size: 24px; font-weight: bold;">ì´ë¦„ ë˜ëŠ” ë‹‰ë„¤ì„ì„ ì…ë ¥í•´ì£¼ì„¸ìš” ğŸš— </p>', unsafe_allow_html=True)
    user_id_input = st.text_input("ë‹‰ë„¤ì„ ì…ë ¥", placeholder="ë‹‰ë„¤ì„ì„ ì…ë ¥í•˜ì„¸ìš”", label_visibility="hidden")
    if user_id_input:
        st.session_state["user_id"] = user_id_input
        st.rerun()
    st.stop()

user_id = st.session_state["user_id"]

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë° ì‚¬ìš©ì ìƒíƒœ í™•ì¸
if "messages" not in st.session_state:
    st.session_state.messages = []
    is_existing_user = False
    
    # CSVì—ì„œ ê¸°ì¡´ ì‚¬ìš©ì ë©”ì‹œì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(chat_history_csv_path):
        try:
            df = pd.read_csv(chat_history_csv_path)
            user_msgs_df = df[df["user_id"] == user_id]
            if not user_msgs_df.empty:
                is_existing_user = True
                for _, row in user_msgs_df.iterrows():
                    st.session_state.messages.append({"role": "user", "content": row["content"]})
        except Exception as e:
            st.warning(f"ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    # ì‚¬ìš©ì ìƒíƒœì— ë”°ë¥¸ í™˜ì˜ ë©”ì‹œì§€
    if is_existing_user:
        st.markdown(f'<h3 style="color: white; font-size: 28px; font-weight: bold;">ğŸ {user_id}ë‹˜, ë‹¤ì‹œ ì˜¤ì…¨ë„¤ìš”! ì´ì „ ëŒ€í™”ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.</h3>', unsafe_allow_html=True)
        st.markdown('<p style="color: #ffcc00; font-size: 20px; font-weight: bold;">â¬‡ï¸ ì•„ë˜ì—ì„œ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!</p>', unsafe_allow_html=True)
    else:
        st.markdown(f'<h3 style="color: white; font-size: 28px; font-weight: bold;">ğŸ {user_id}ë‹˜, ì²˜ìŒ ì˜¤ì…¨ë„¤ìš”! í™˜ì˜í•©ë‹ˆë‹¤!</h3>', unsafe_allow_html=True)
        st.markdown('<p style="color: #ffcc00; font-size: 20px; font-weight: bold;">ğŸ’¬ ì•„ë˜ ì±„íŒ…ì°½ì— ì›í•˜ì‹œëŠ” ì°¨ëŸ‰ ì¡°ê±´ì„ ë§ì”€í•´ì£¼ì„¸ìš”!</p>', unsafe_allow_html=True)
else:
    # ì„¸ì…˜ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš° (í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ë“±)
    st.markdown(f'<h3 style="color: white; font-size: 24px;">ğŸ {user_id}ë‹˜, ë‹¹ì‹ ì—ê²Œ ë§ëŠ” ìµœì ì˜ ì°¨ëŸ‰ì„ ì¶”ì²œí•˜ê² ìŠµë‹ˆë‹¤!</h3>', unsafe_allow_html=True)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
prompt_template = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ ìë™ì°¨ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    
ì‚¬ìš©ìì˜ ì´ì „ ëŒ€í™” ê¸°ë¡ê³¼ ìµœê·¼ ì…ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì°¨ëŸ‰ì„ 3ìˆœìœ„ ì¶”ì²œí•˜ê³  ì¶”ì²œ ì´ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ìë™ì°¨ ëª©ë¡:
{car_documents}

ì´ì „ ëŒ€í™” ê¸°ë¡:
{chat_history}"""),
    ("human", "{user_input}")
])

# LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini")

# ì²´ì¸ ìƒì„± (LCEL)
chain = prompt_template | llm

# ì±„íŒ… ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def format_chat_history():
    if not st.session_state.messages:
        return "ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
    
    history_text = ""
    for i, msg in enumerate(st.session_state.messages, 1):
        history_text += f"{i}. ì‚¬ìš©ì: {msg['content']}\n"
    return history_text

# ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if user_input := st.chat_input("ì–´ë–¤ ì°¨ëŸ‰ì„ ì°¾ê³  ê³„ì‹ ê°€ìš”? (ì˜ˆ: ì „ê¸°ì°¨, SUV)"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ ì¶œë ¥
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.spinner(""):
        # ìŠ¤í”¼ë„ˆ í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ í‘œì‹œ (í°ìƒ‰)
        spinner_placeholder = st.empty()
        spinner_placeholder.markdown('<p style="color: white; font-size: 16px; font-weight: bold;">ì°¨ëŸ‰ì„ ì¶”ì²œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤ ğŸï¸ ğŸï¸ ğŸï¸</p>', unsafe_allow_html=True)
        try:
            # ì²´ì¸ ì‹¤í–‰
            inputs = {
                "user_input": user_input,
                "car_documents": "\n".join(car_docs),
                "chat_history": format_chat_history()
            }
            response = chain.invoke(inputs)
            bot_reply = response.content
            
        except Exception as e:
            bot_reply = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ì²œ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    # ì‚¬ìš©ì ì…ë ¥ì„ CSVì— ì €ì¥
    try:
        new_row = {"user_id": user_id, "content": user_input}
        header_flag = not os.path.exists(chat_history_csv_path)
        pd.DataFrame([new_row]).to_csv(chat_history_csv_path, mode="a", index=False, header=header_flag, encoding='utf-8')
    except Exception as e:
        st.warning(f"ì±„íŒ… ê¸°ë¡ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # ì±—ë´‡ ì‘ë‹µ ì¶œë ¥ (í°ìƒ‰ ê¸€ì”¨ë¡œ í‘œì‹œ)
    with st.chat_message("assistant"):
        st.markdown(f'<div style="color: white; font-size: 20px;">{bot_reply}</div>', unsafe_allow_html=True)